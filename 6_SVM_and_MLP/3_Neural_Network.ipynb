{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Mạng thần kinh nơ-ron nhân tạo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khái quát về neural network\n",
    "Con người có khả năng nhận biết thế giới xung quanh thông qua việc tiếp thu các thông tin, đặc điểm của các sự vật, hiện tượng. Điển hình, khi chúng ta nhìn thấy một chiếc xe, một cái cây, chúng ta có thể ngay lập tức nhận ra chúng bằng cách nhận ra các đặc điểm chung đặc trưng cho chiếc xe hoặc cái cây. Cụ thể với chiếc xe, con người đã nhìn thấy hàng triệu chiếc xe các loại khác nhau và nhận ra những đặc điểm chung của những chiếc xe. Từ đó suy ra, mỗi vật thể nào có những đặc điểm ấy ta nói rằng đó là một chiếc xe. Đối với cái cây hay bất kỳ sự vật, hiện tượng nào, con người cũng quan sát và rút ra nhận xét như vậy.\n",
    "\n",
    "Để có thể tạo ra các thuật toán có khả năng quan sát và rút ra đặc điểm sự vật như con người, hiện nay chưa có phương pháp nào tốt hơn là mô phỏng lại cách thức hoạt động của não người. Sơ lược qua về sinh học, thì não người bao gồm hàng tỷ các tế bào thần kinh gọi là neuron (nơ ron), các tế bào này liên kết với nhau và tạo thành một mạng lưới liên kết chặt chẽ, tất cả mọi thông tin thu được về từ năm giác quan (thị giác, khứu giác, thính giác, xúc giác, vị giác) đều được truyền qua mạng lưới các tế bào này để phân tích và đưa ra các quyết định của con người.\n",
    "\n",
    "Thuật toán mô phỏng như vậy được gọi là Neural Network.\n",
    "\n",
    "Tuy nhiên với năng lực xử lý tính toán của máy tính hiện nay, cũng như giới hạn về hiểu biết về não người, chúng ta chỉ có thể mô phỏng một mạng lưới rất nhỏ với cấu trúc đơn giản hơn rất nhiều so với não người.\n",
    "## Perceptrons\n",
    "\n",
    "![Perceptron Visualization](perceptrons.png)\n",
    "\n",
    " Perceptron là một mạng neural network đơn giản nhất. Nó chỉ có duy nhất một tế bào neuron để xử lý thông tin nhận vào từ lớp đầu vào (input layer).\n",
    "\n",
    "Input layer là lớp nhận dữ liệu đầu vào. Ví dụ như tai chúng ta nghe âm thanh, sẽ thu lại thông tin về trường độ, cao độ, độ to thì trường độ, cao độ, độ to chính là các đầu vào $x_1, x_2, .., x_n$. Các thông tin đầu vào được gọi chung là *features* của dữ liệu.\n",
    "\n",
    "Các thông tin $x_1, x_2, x_3, ..., x_n$ được biểu diễn thành một ma trận, và truyền tới neuron bằng cách nhân với một ma trận trọng số gọi là *weight*, các phần tử của *weight* được biểu diễn trong ảnh bằng các tham số $w_1, w_2, w_3, ..., w_n$\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{bmatrix}\n",
    "        x_1 & x_2 & x_3 & ... & x_n\n",
    "    \\end{bmatrix}\n",
    "    %\n",
    "    \\begin{bmatrix}\n",
    "        w_1 \\\\ \n",
    "        w_2 \\\\\n",
    "        w_3 \\\\\n",
    "        ... \\\\\n",
    "        w_n\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        x_1w_1 + x_2w_2 + x_3w_3 + ... + x_nw_n\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "## Artificial Neural Network (Multi-layer Perceptron)\n",
    "Chúng ta vừa tìm hiểu khái niệm về *perception*, tuy nhiên *perception* quá đơn giản chỉ bao gồm mỗi một *neuron* duy nhất, với cấu trúc đơn giản như thế này, chúng ta chỉ có thể giải được các bài toán đơn giản, không thể mô phỏng lại não người để giải quyết các bài toán phức tạp, do đó chúng ta cần mở rộng ra thành nhiều *neuron*. Mạng bao gồm nhiều *neuron* được gọi là *multilayer perceptron* hay còn biết đến với cái tên *artificial neural network (mạng thần kinh nhân tạo)* \n",
    "\n",
    "![Neural Network Visualization](nn.png)\n",
    "\n",
    "Trong hình minh họa phía trên chúng ta có thể thấy ngoài việc lớp output layer đã bổ sung thành 2 neuron, còn bổ sung thêm một hidden layer ở giữa với nhiều neuron trong một lớp.\n",
    "\n",
    "Trong mạng neuron, người ta gọi lớp đầu tiên là *input layer* vì nó nhận *features*, còn lớp cuối là *output layer* vì nó trả lại kết quả đầu ra, còn lại tất cả các lớp ở giữa đều được gọi là *hidden layer*\n",
    "## Các phương pháp huấn luyện ANN\n",
    "### Feed-Forward (Huấn luyện xuôi)\n",
    "Tại mỗi lớp (layer) trừ input layer sẽ nhận đầu vào là layer trước nhân với ma trận *weights* (trọng số) tương ứng, cứ như thế lớp này nhân ma trận *weights* là input của lớp sau, lan truyền như vậy đến output layer thì kết thúc\n",
    "### Back-Propagation (Lan truyền ngược)\n",
    "Trong lan truyền xuôi, các layer đằng trước không nhận được thông tin và không biết gì về các layer đằng sau, cụ thể là trong mô hình phía trên ta khó có thể biết được khi thay đổi ma trận *weights* của input layer thì nó ảnh gì tới output layer. Do đó người dùng đạo hàm, và áp dụng quy tắc *chuỗi đạo hàm đa biến (chain rule)* để các layer không kết nối trực tiếp như input layer và output layer có được thông tin của nhau. Và chúng ta có 2 kiểu đạo hàm là tiến và ngược. Trong khuôn khổ bài viết này, chúng ta không bàn tới đạo hàm tiến và ngược vì để phân tích và so sánh chúng ta cần hiểu biết về giải tích và khái niệm *computational graph*, tuy nhiên nhìn vào cái tên chúng ta có thể dự đoán được là thuật toán này sử dụng đạo hàm ngược. Và lí do tại sao lại sử dụng đạo hàm ngược sao? Với một hàm số 1 triệu biến, đạo ngược sẽ nhanh gấp 1 triệu lần đạo hàm tiến."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triển khai ANN với thư viện scikit-learn\n",
    "### Chuẩn bị dữ liệu\n",
    "Scikit-learn là một thư viện tính toán số học và machine learning mạnh mẽ, dễ học , dễ dùng\n",
    "\n",
    "Ngoài ra, chúng ta còn cần một thư viện để xử lý dữ liệu, vì dữ liệu thường không ở dạng ma trận luôn, mà được viết ở các dạng chưa chuẩn như là file excel, ... Để đọc và xử lý dữ liệu, chúng ta thường sử dụng thư viện pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo thư viện\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong bài này chúng ta sử dụng bộ dữ liệu iris là một bộ dữ liệu phân loại hoa diên vĩ dựa trên các đặc điểm về hình dạng của bông hoa.\n",
    "\n",
    "Trước hết chúng ta tiến hành tải và nạp dữ liệu vào máy bằng thư viện pandas\n",
    "\n",
    "Đường dẫn để tải dữ liệu"
   ]
  },
  {
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tên các cột dữ liệu, phần này được mô tả trên website của bộ dữ liệu iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link='/home/thinh-do/Hoc_Tap/Machine_Learning_Basic/5_Binary_Classification/2.Logistic_regresion/Tự luyện/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành nạp dữ liệu vào máy tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(link, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta xem thử 5 mẫu dữ liệu đầu như thế nào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tác giả của bộ dữ liệu này đã trộn cả class (nhãn) vào trong cùng với features, ta cần phải tách riêng nhãn và features ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.iloc[:, :4]\n",
    "labels = dataset.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thử ra 5 mẫu dữ liệu đầu của tập features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal-length  sepal-width  petal-length  petal-width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thử ra 5 mẫu dữ liệu đầu của tập labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class\n",
      "0  Iris-setosa\n",
      "1  Iris-setosa\n",
      "2  Iris-setosa\n",
      "3  Iris-setosa\n",
      "4  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tập các giá trị phân biệt của labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "print(labels.Class.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuy nhiên, công việc xử lý dữ liệu chưa xong, chúng ta không nào đưa nhãn dưới dạng string vào mạng ANN được, cần phải ánh xạ các string đó thành số để có thể tính toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = labels.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta lại in thử ra 5 mẫu dữ liệu đầu của labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n"
     ]
    }
   ],
   "source": [
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các giá trị phân biệt của labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(labels.Class.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy chúng ta đã tiến hành ánh xạ thành công từ kiểu dữ liệu string sang thành số để có thế tính toán được.\n",
    "\n",
    "Thông thường, chúng ta có một bộ dữ liệu lớn thì phải chia thành 2 phần: training và validation.\n",
    "\n",
    "Trong quá trình training chúng ta để nguyên bộ validation, sau khi train xong, chúng sẽ sử dụng bộ validation như một bài kiểm tra để đánh giá độ hiệu quả của model, và tỉ lệ thông thường sẽ là chia 5, bộ train 4, bộ validation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_valid, labels_train, labels_valid = train_test_split(features, labels, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra còn một kỹ thuật được gọi là *Feature Scaling*\n",
    "\n",
    "Nếu giá trị giữa các feature của chúng ta lệch nhau lớn, sẽ làm cho đồ thị của chúng bị rất méo, khiến quá trình training khó hội tụ. Do đó người ta thường chỉnh lại để làm sao miền giá trị của các cột tương đương nhau, khiến đồ thị đều, nhanh hội tụ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(features_train)\n",
    "\n",
    "features_train = scaler.transform(features_train)\n",
    "features_valid = scaler.transform(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta thử quan lại 5 mẫu dữ liệu ban đầu một lần nữa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0295396   0.03726262  1.04885915  1.61353854]\n",
      " [-1.00757077  0.26083837 -1.40918627 -1.28030775]\n",
      " [-1.00757077  0.70798987 -1.18572759 -1.01723082]\n",
      " [-0.88774075  1.60229286 -1.18572759 -1.28030775]\n",
      " [-1.24723081  0.70798987 -1.18572759 -1.28030775]]\n"
     ]
    }
   ],
   "source": [
    "print(features_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy dữ liệu của chúng ta đã chuyển sang dạng ma trận, và có miền giá trị tương đương nhau, không lệch như ban đầu\n",
    "### Huấn luyện và phục vụ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ sử dụng 3 hiden layers, lớp hidden thứ nhất gồm 10 neuron, lớp thứ 2 gồm 7 neuron và lớp thứ 3 gồm 5 neuron. Input và output sẽ được tự động nhận diện để điều chỉnh kích thước. max_iter là số lần huấn luyện, ở đây chúng ta huấn luyện 2000 lần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 7, 5), max_iter=2000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra nếu chúng ta để ý thì hiện nay labels train đang ở dạng ma trận 2 chiều, và chúng buộc phải kéo nó sang dạng mảng 1 chiều. Để kéo một ma trận 2 chiều sang dạng mảng 1 chiều, ta sử dụng phương thức numpy.ndarray.ravel(). Lí do tại chúng ta dùng pandas để nạp dữ liệu, mà bây giờ lại dùng numpy để chuẩn hóa dữ liệu, đó vì pandas ngầm sử dụng numpy để lưu dữ liệu các tensor.\n",
    "\n",
    "Bây giờ chúng ta tiến hành đập phẳng ma trận 2 chiều sang dạng mảng 1 chiều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_1d = labels_train.values.ravel()\n",
    "labels_valid_1d = labels_valid.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 7, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(features_train, labels_train_1d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta tiến hành chạy thử model với tâp validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(features_valid)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ra kết quả chạy thử với tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 2 0 0 1 1 0 2 1 0 1 2 2 0 0 1 1 0 2 2 2 1 2 2 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá model\n",
    "Đối với dạng bài classification, người ta thường hay dùng accuracy score làm thước đo (metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy của model: 96.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_valid_1d, predictions)\n",
    "print(\"Accuracy của model: {}%\".format(round(accuracy*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}