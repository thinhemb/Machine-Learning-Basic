{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MỞ ĐẦU \n",
    "\n",
    "phần này sau khi học SVM quay lại học để hiểu rõ hơn và so sánh (nhưng vẫn đọc phần dưới)\n",
    "\n",
    "Như chúng ta đã biết SVM là một trong hai phương pháp phân loại phổ biến nó phân loại dự trên hàm hinge loss.  Và phương pháp phân loại còn lại là Softmax. Điểm khác biệt giữa Softmax và SVM đó là hàm mất mát khác nhau. Nếu như hàm mất mát của SVM đánh giá mức độ hài lòng về chấm điểm phù hợp với class từ một điểm dữ liệu. Còn Soft max thì nó cụ thể hơn đó là xác xuất được chuẩn hóa tức là xác xuất của dữ liệu i vào lớp thứ j là bao nhiêu phần trăm. Nhìn chung ta có cách nhìn trực quan hơn. Bởi lẽ chúng ta đều hỏi xác xuất nhưng về điểm chúng ta khá mơ hồ về chúng.\n",
    "\n",
    "Đối với SVM hàm số $f(x_i; W) = W x_i$ là điểm số, còn với Soft max sẽ là xác xuất. Và thay thế cho hàm hinge loss của SVM, Softmax cung cấp một hàm mất mát cross-entropy loss có dạng :\n",
    "\n",
    "$L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) \\hspace{0.5in} \\text{or equivalently} \\hspace{0.5in} L_i = -f_{y_i} + \\log\\sum_j e^{f_j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax sẽ lấy một giá trị của một vector, sau đó nén chúng lại dạng xác xuất trong đoạn [0,1] và tổng xác xuất của điểm dữ liệu đó trong các class bằng 1.\n",
    "\n",
    "Vấn đề thực tế : Trong thực tế khi bạn viết mã cho việc tính toán hàm Softmax các phép toán trung gian $e^{f_{y_i}}$ và $\\sum_j e^{f_j}$ có thể rất lớn do hàm mũ, điều đó khiến dữ liệu không ổn định vì vậy chúng ta cần thực hiện thao tác chuẩn hóa dữ liệu nếu chúng ta nhân đỉnh và đáy của phân số với một hằng số C và đẩy nó vào tổng, chúng ta sẽ nhận được biểu thức (tương đương về mặt toán học) sau đây:\n",
    "\n",
    "$\\frac{e^{f_{y_i}}}{\\sum_j e^{f_j}}\n",
    "= \\frac{Ce^{f_{y_i}}}{C\\sum_j e^{f_j}}\n",
    "= \\frac{e^{f_{y_i} + \\log C}}{\\sum_j e^{f_j + \\log C}}$\n",
    "\n",
    "Một cách lựa chọn phổ biến chúng ta thường sử dụng đó là lựa chọn $\\log C = -\\max_j f_j$\n",
    "\n",
    "\n",
    "Một số khái niêm cần nhớ:\n",
    "\n",
    "    1. One hot coding\n",
    "    \n",
    "    2. Cross Entropy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÁP DỤNG VỚI THƯ VIỆN SKLEARN GIẢI QUYẾT BÀI TOÁN BỘ DỮ LIỆU CIFA-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để sử dụng Softmax Regression, ta cần thêm một vài thuộc tính nữa:\n",
    "linear_model.LogisticRegression(C=1e5, solver = 'lbfgs', multi_class = 'multinomial')\n",
    "Với Logistic Regression, multi_class = 'ovr' là giá trị mặc định, tương ứng với one-vs-rest. solver = 'lbfgs' là một phương pháp tối ưu cũng dựa trên gradient nhưng hiệu quả hơn và phức tạp hơn Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        datadict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    Y = datadict[b'labels']\n",
    "    X = datadict[b'data']\n",
    "    \n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "def load_CIFAR10(ROOT):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = unpickle(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = unpickle(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện import thư viện và load dữ liệu và các mảng sau đó tiến hành chuyển các mảng đó sang ma trận để có thể dễ dàng thực hiện thuật toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\nTraining labels shape:  (50000,)\nTest data shape:  (10000, 32, 32, 3)\nTest labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# link dataset:  https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print ('Training data shape: ', X_train.shape)\n",
    "print ('Training labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data shape:  (50000, 3072)\nTraining labels shape:  (50000,)\nTest data shape:  (10000, 3072)\nTest labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print ('Training data shape: ', X_train.shape)\n",
    "print ('Training labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có dữ liệu 2 loại là train và test rồi bây giờ chỉ cần cho hàm chạy thực hiện mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hiệu quả mô hình theo Softmax là : 40.42 %\n",
      "/home/thinh-do/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression(C = 1e5,solver = 'lbfgs', multi_class = 'multinomial').fit(X_train, y_train)\n",
    "# Dự đoán mô hình và đánh giá kết quả.\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Hiệu quả mô hình theo Softmax là : %.2f %%\" %(100*accuracy_score(y_test, y_pred.tolist())) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khá tốt đấy chứ nhỉ trọng khi chúng ta không cần phải làm gì nhiều thì đã được kết quả thế này. \n",
    "So sánh với SVM xem sao nhỉ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asanyarray(y_train)\n",
    "\n",
    "mean = np.mean(X_train, axis = 0)\n",
    "X_train = X_train - mean\n",
    "X_test  = X_test - mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf', degree = 3, gamma=1, C = 100)\n",
    "clf.fit(X_train1, y_train1)\n",
    "# Dự đoán mô hình và đánh giá kết quả.\n",
    "\n",
    "y_pred = clf.predict(X_test1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Hiệu quả mô hình theo SVM là : %.2f %%\" %(100*accuracy_score(y_test, y_pred.tolist())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}